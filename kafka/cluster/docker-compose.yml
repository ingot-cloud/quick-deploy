version: "3.8"

services:
  ##############################################################
  # Kafka Cluster - 3 节点企业级配置（KRaft 模式）
  ##############################################################

  ##############################################################
  # Broker 1
  ##############################################################
  kafka-broker-1:
    # Kafka 官方镜像（私有仓库镜像等价于 apache/kafka:3.8.0）
    image: docker-registry.ingotcloud.top/apache/kafka:3.8.0
    # Broker1 的容器名，方便 docker logs / exec
    container_name: ${CLUSTER_BROKER1_NAME}
    restart: always

    ports:
      # 对外暴露给业务系统的端口（宿主机:CLUSTER_BROKER1_PORT → 容器:9092）
      - "${CLUSTER_BROKER1_PORT}:9092"               # EXTERNAL：外部客户端访问 Kafka
      # KRaft controller 使用的端口（宿主机:CLUSTER_BROKER1_CONTROLLER_PORT → 容器:9093）
      - "${CLUSTER_BROKER1_CONTROLLER_PORT}:9093"   # CONTROLLER：KRaft 控制器端口
      # 29092:29092 不需要映射，INTERNAL listener 容器内部访问使用

    environment:
      ##########################################################
      # =============== 1. 基础 KRaft 配置（官方格式） ==========
      ##########################################################
      # 当前节点在 KRaft 中同时承担 broker 和 controller 角色
      KAFKA_PROCESS_ROLES: "broker,controller"
      # 当前 broker 的节点 ID，必须唯一，对应 CLUSTER_CONTROLLER_SERVERS 中的 id
      KAFKA_NODE_ID: ${CLUSTER_BROKER1_ID}
      # KRaft controller 投票节点配置，3 节点写在环境变量 CLUSTER_CONTROLLER_SERVERS 中
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${CLUSTER_CONTROLLER_SERVERS}
      # controller 对外暴露的 listener 名称，和 KAFKA_LISTENERS 中 CONTROLLER 对应
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # 集群 ID，生产环境建议通过 kafka-storage.sh 生成后固定下来
      KAFKA_CLUSTER_ID: "${CLUSTER_ID}"
      # 禁止自动创建 topic，强制通过运维/平台创建，防止误拼写产生脏 topic
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false

      # 集群环境下的内部 topic 副本配置（企业级：3 副本 + 最小 ISR=2）
      # consumer offset 存储 topic 的副本数，生产环境强烈建议 3 副本
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${CLUSTER_OFFSETS_TOPIC_REPLICATION_FACTOR}
      # 事务状态日志副本数
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${CLUSTER_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
      # 事务状态日志最小同步副本数，保证写入可靠性（通常为 副本数-1）
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${CLUSTER_TRANSACTION_STATE_LOG_MIN_ISR}

      ##########################################################
      # =============== 2. Listener / 网络配置 ==================
      ##########################################################
      # 每个 listener 的安全协议，目前全部为 PLAINTEXT，后续如接入 SASL/SSL 可在此扩展
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >
        INTERNAL:PLAINTEXT,
        EXTERNAL:PLAINTEXT,
        CONTROLLER:PLAINTEXT

      # 集群内部（broker 之间 + 容器内客户端）访问使用 INTERNAL
      # 宿主机 / 外部系统访问使用 EXTERNAL
      # controller 使用单独的 CONTROLLER listener
      KAFKA_LISTENERS: >
        INTERNAL://:29092,
        EXTERNAL://:9092,
        CONTROLLER://:9093

      # advertised.listeners：告诉客户端真正访问的地址
      # INTERNAL 使用 docker 内部 DNS 名称，EXTERNAL 使用宿主机 IP/域名 + 暴露端口
      KAFKA_ADVERTISED_LISTENERS: >
        INTERNAL://kafka-broker-1:29092,
        EXTERNAL://${CLUSTER_BROKER1_HOST}:${CLUSTER_BROKER1_PORT}

      # broker 之间内部通信使用 INTERNAL listener，避免走对外暴露端口
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      ##########################################################
      # =============== 2.1 Topic 默认策略（企业级） ============
      ##########################################################
      # 默认分区数，避免业务未指定分区时全部落到单分区
      KAFKA_NUM_PARTITIONS: 12
      # 默认副本数，生产环境建议与集群副本策略保持一致（3 副本）
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      # 普通 topic 的最小 ISR，保证有至少 2 副本成功写入才算成功
      KAFKA_MIN_INSYNC_REPLICAS: 2

      ##########################################################
      # =============== 3. 日志与存储优化 =======================
      ##########################################################
      # Kafka 数据目录，挂到外部数据盘上
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

      # 单个日志 segment 大小：1GB，方便压缩和迁移
      KAFKA_LOG_SEGMENT_BYTES: 1073741824        # 1GB segment
      # 时间维度的保留策略：3 天（可根据业务需要调整）
      KAFKA_LOG_RETENTION_HOURS: 72              # 保留 3 天
      # 空间维度的保留策略：150GB（单 broker 上限，需结合磁盘容量调整）
      KAFKA_LOG_RETENTION_BYTES: 150000000000    # 最大 150GB
      # 开启 compact 支持，支持以 key 为维度的压缩日志（如 offset/状态类 topic）
      KAFKA_LOG_CLEANER_ENABLE: "true"

      ##########################################################
      # =============== 4. 性能优化（适配 8 核 CPU） ============
      ##########################################################
      # 网络线程数：适配 8 核机器的典型配置
      KAFKA_NUM_NETWORK_THREADS: 8
      # I/O 线程数：负责磁盘读写
      KAFKA_NUM_IO_THREADS: 16
      # socket 发送缓冲区
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      # socket 接收缓冲区
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      # 单个请求最大大小（包含批量消息）
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600  # 100MB

      ##########################################################
      # =============== 5. JVM 优化 =================
      ##########################################################
      # 堆大小，可根据物理内存和负载调整
      KAFKA_HEAP_OPTS: "${BROKER_HEAP_OPTS}"
      # JVM GC 等优化参数
      KAFKA_JVM_PERFORMANCE_OPTS: >
        -server
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=20

    volumes:
      # 将 Kafka 数据目录挂载到宿主机指定路径，避免容器销毁导致数据丢失
      - ${CLUSTER_BROKER1_VOLUME}:/var/lib/kafka/data
    env_file:
      # 使用当前目录下的 .env 文件统一管理可变参数
      - ./.env

  ##############################################################
  # Broker 2
  ##############################################################
  kafka-broker-2:
    image: docker-registry.ingotcloud.top/apache/kafka:3.8.0
    container_name: ${CLUSTER_BROKER2_NAME}
    restart: always

    ports:
      # Broker2 对外暴露端口
      - "${CLUSTER_BROKER2_PORT}:9092"
      - "${CLUSTER_BROKER2_CONTROLLER_PORT}:9093"

    environment:
      # 同 Broker1：broker + controller 角色
      KAFKA_PROCESS_ROLES: "broker,controller"
      # Broker2 的节点 ID，必须与 Broker1 / Broker3 不同
      KAFKA_NODE_ID: ${CLUSTER_BROKER2_ID}
      # 与 Broker1 共用同一套 controller quorum 配置
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${CLUSTER_CONTROLLER_SERVERS}
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CLUSTER_ID: "${CLUSTER_ID}"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false

      # 内部 topic 副本配置保持与 Broker1 一致
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${CLUSTER_OFFSETS_TOPIC_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${CLUSTER_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${CLUSTER_TRANSACTION_STATE_LOG_MIN_ISR}

      # Listener 协议配置：全部 PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >
        INTERNAL:PLAINTEXT,
        EXTERNAL:PLAINTEXT,
        CONTROLLER:PLAINTEXT

      # Listener 端口绑定，与 Broker1 相同，仅宿主机映射端口不同
      KAFKA_LISTENERS: >
        INTERNAL://:29092,
        EXTERNAL://:9092,
        CONTROLLER://:9093

      # advertised.listeners：内部使用容器名，外部使用宿主机地址
      KAFKA_ADVERTISED_LISTENERS: >
        INTERNAL://kafka-broker-2:29092,
        EXTERNAL://${CLUSTER_BROKER2_HOST}:${CLUSTER_BROKER2_PORT}

      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # 日志目录及相关策略保持与 Broker1 一致
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_HOURS: 72
      KAFKA_LOG_RETENTION_BYTES: 150000000000
      KAFKA_LOG_CLEANER_ENABLE: "true"

      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600

      KAFKA_HEAP_OPTS: "${BROKER_HEAP_OPTS}"
      KAFKA_JVM_PERFORMANCE_OPTS: >
        -server
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=20

    volumes:
      - ${CLUSTER_BROKER2_VOLUME}:/var/lib/kafka/data
    env_file:
      - ./.env

  ##############################################################
  # Broker 3
  ##############################################################
  kafka-broker-3:
    image: docker-registry.ingotcloud.top/apache/kafka:3.8.0
    container_name: ${CLUSTER_BROKER3_NAME}
    restart: always

    ports:
      # Broker3 对外暴露端口
      - "${CLUSTER_BROKER3_PORT}:9092"
      - "${CLUSTER_BROKER3_CONTROLLER_PORT}:9093"

    environment:
      # 同 Broker1：broker + controller 角色
      KAFKA_PROCESS_ROLES: "broker,controller"
      # Broker3 的节点 ID
      KAFKA_NODE_ID: ${CLUSTER_BROKER3_ID}
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${CLUSTER_CONTROLLER_SERVERS}
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CLUSTER_ID: "${CLUSTER_ID}"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${CLUSTER_OFFSETS_TOPIC_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${CLUSTER_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${CLUSTER_TRANSACTION_STATE_LOG_MIN_ISR}

      # Listener 协议配置：全部 PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >
        INTERNAL:PLAINTEXT,
        EXTERNAL:PLAINTEXT,
        CONTROLLER:PLAINTEXT

      # Listener 端口绑定，与其他 broker 相同
      KAFKA_LISTENERS: >
        INTERNAL://:29092,
        EXTERNAL://:9092,
        CONTROLLER://:9093

      # advertised.listeners：内部使用容器名，外部使用宿主机地址
      KAFKA_ADVERTISED_LISTENERS: >
        INTERNAL://kafka-broker-3:29092,
        EXTERNAL://${CLUSTER_BROKER3_HOST}:${CLUSTER_BROKER3_PORT}

      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_HOURS: 72
      KAFKA_LOG_RETENTION_BYTES: 150000000000
      KAFKA_LOG_CLEANER_ENABLE: "true"

      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600

      KAFKA_HEAP_OPTS: "${BROKER_HEAP_OPTS}"
      KAFKA_JVM_PERFORMANCE_OPTS: >
        -server
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=20

    volumes:
      - ${CLUSTER_BROKER3_VOLUME}:/var/lib/kafka/data
    env_file:
      - ./.env

  ##############################################################
  # AKHQ - Kafka 可视化管理界面（连接整个集群）
  ##############################################################
  akhq:
    # AKHQ 可视化管理界面
    image: docker-registry.ingotcloud.top/tchiotludo/akhq:0.26.0
    # AKHQ 容器名称
    container_name: ${CLUSTER_AKHQ_NAME}
    restart: always
    ports:
      # 宿主机访问 AKHQ 的端口（宿主机:CLUSTER_AKHQ_PORT → 容器:8080）
      - "${CLUSTER_AKHQ_PORT}:8080"  # AKHQ web 界面端口
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            cluster:
              properties:
                # AKHQ 运行在同一个 Docker 网络里，直接访问 broker 内部地址
                bootstrap.servers: "kafka-broker-1:29092,kafka-broker-2:29092,kafka-broker-3:29092"
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    env_file:
      - ./.env


